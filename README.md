# Getting and Cleaning Data: Course Project

#### *September 2015*

*Abstract:* A script created for performing data manipulation tasks on ["Human Activity Recognition Using Smartphones Data Set"](http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones), outlined in course project assignment.

### Introduction

Assignment for the *Getting and Cleaning Data* course project was to create a script, which takes ["Human Activity Recognition Using Smartphones Data Set"](http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) and does the following:

1. Merges the training and the test sets to create one data set.
2. Extracts only the measurements on the mean and standard deviation for each measurement. 
3. Uses descriptive activity names to name the activities in the data set
4. Appropriately labels the data set with descriptive variable names. 
5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.

### Data set description

According to the ["Data Set Information"](http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) a database was built from the recordings of 30 volunteers within an age bracket of 19-48 years performing activities of daily living (walking, walking upstairs, walking downstairs, sitting, standing, laying) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, research team captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. 

Data set for the course project is downloadable here: ["https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"](https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip).

Structure and contents of a data set are described in `README.txt`, which is included within an archive.

### Submission contents

  - `codebook.md` - Describes the experiment data and the steps taken to summarize the data.
  - `run_analysis.R` - R script to merge, clean-up, transform, and summarize the experiment data.
  - `tidy_dataset.txt` - Output file generated by the `run_analysis.R` script.
  - `readme.md` - This file.

### Getting started

Before running the `run_analysis.R` script in R please follow these steps:

1. Unpack the `getdata-projectfiles-UCI HAR Dataset.zip` file;
2. Please make sure `run_analysis.R` and `UCI HAR Dataset` folder are in your working directory;
3. Make sure you have [dplyr](https://cran.r-project.org/web/packages/dplyr/index.html) and [magrittr](https://cran.r-project.org/web/packages/magrittr/index.html) packages installed, since the script depends on them.

### Exploring the data

Let's try to figure out how the data components actually look like and how parts should be merged together.

The first component we will look into is `activity_labels` table. It has 6 activity names and their numeric IDs. Since `y_train` and `y_test` both have unique values ranging from 1 to 6,  those are, obviously, activity IDs, which are to substituted with descriptive names later.

Next, `x_train` and `x_test` tables both have 561 variables. That corresponds to 561 records listed in `features` table, which holds feature IDS and their names. Thus feature names from `features` table should be assigned to column names of both `x_train` and `x_test` tables.

Now let's figure out how the `x`, `y` and `subject` components of the data should be combined. We have already found out, that `x` component is the data from the sensors (since it holds observations for each measured feature), `y` - is an activity identifier (6 unique values as in activity labels) and `subject` - is an identifier of the subject who carried out the experiment. For each of the `test` data components there are 2947 observations, while for `train` data observation count is 7352. This means tables `x`, `y` and `subject` should be  combined columnwise within `test` and `train` data partitions accordingly.

Finally, since data set has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data, the two partitions should be merged back again by adding `test` rows to `train` rows.

### A note on *"Inertial Signals"*

Tables within `Inertial Signals` folders have 128 variables. And since we do not have a corresponding table with names for those variables we cannot properly fit them into earlier outlined frame. Thus a decision is taken to omit the data contained within `Inertial Signals` folders.

### Data manipulation sequence

Data manipulation carried out by the script is performed in a following sequence:

1. Activity labels are read into the workspace with descriptive  column names `"Activity.ID"` and `"Activity.Name"`.
2. Feature labels are read into the workspace with descriptive column names `"Feature.ID"`, `"Feature.Name"`.
3. `train` and `test` data is read into the workspace with descriptive column names (`"Subject"`, `"Activity"`). `x` table data is read into the workspace with labels from `"Feature.Name"` column of `feature_labels` table.
4. `Subject`, `Activity` and `Features` components (feature measurements are put within `measures_raw` data frame for further processing)  of `test` and `train` partitions are merged by rows.
5. Descriptive activity names are assigned to activity data.
6. `Subject`, `Activity` and `Features` components are merged into complete data set (`complete_dataset_raw`) by columns.
7. `Mean` and `Standard Deviation` columns are extracted from `Features` component and combined within `measures_tidy` data frame. 
8. A data set, which contains only `Mean` and `Standard Deviation` related variables is assembled by merging `Subject`, `Activity` with an output from previous step.
9. An independent tidy data set with the average of each variable for each activity and each subject is created and written into `tidy_dataset.txt`.

### A note on *"tidy"* aspects of outcome data

In manipulation step 5 descriptive activity names are assigned to activities IDs of the data set, as it is required in part 3 of the assignment. Variables, which contained `-mean` and `-std` now contain `Mean` and `Std` accordingly. Parenthesis and dots were removed from variable names. `BodyBody` was replaced with `Body`.


### Acknowledgement

I would like to mention that this project would be much harder to accomplish without [A really long advice thread for the Project](https://class.coursera.org/getdata-032/forum/thread?thread_id=26).
